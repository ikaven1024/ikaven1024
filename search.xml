<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[slf4j日志中的palceholder]]></title>
    <url>%2F2018%2F07%2F10%2Fslf4j-logger-palceholder%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223// Goodlogger.error("Logger1: ", e);[main] ERROR - Logger1: java.lang.NullPointerException at com.kaven.test.logger.PlaceHolderTest.main(PlaceHolderTest.java:11)// 占位符不能解析logger.error("Logger2: &#123;&#125;", e);[main] ERROR - Logger2: &#123;&#125;java.lang.NullPointerException at com.kaven.test.logger.PlaceHolderTest.main(PlaceHolderTest.java:11)// 占位符能解析，但是没有了堆栈信息(使用了toString())logger.error("Logger2: &#123;&#125;, &#123;&#125;", 3, e);[main] ERROR - Logger2: 3, java.lang.NullPointerException // toString()logger.error("Logger3: " + e);[main] ERROR - Logger3: java.lang.NullPointerException// getMessage()logger.error("Logger4: " + e.getMessage());[main] ERROR - Logger4: null]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring_cloud_contract]]></title>
    <url>%2F2018%2F05%2F28%2Fspring-cloud-contract%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;example.springcloud&lt;/groupId&gt; &lt;artifactId&gt;contract&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud-contract.version&gt;1.2.4.RELEASE&lt;/spring-cloud-contract.version&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-contract-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-contract.version&#125;&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[golang常见陷阱]]></title>
    <url>%2F2018%2F04%2F21%2Fgolang-trap%2F</url>
    <content type="text"><![CDATA[基本内置的数据结构操作是无锁的虽然 Go 语言天生高并发，但内置的数据结构都是非线程安全的。为了实现“原子化”的数据操作，开发者需要自己对数据操作进行加锁。channel 和 sync 都是手动加锁的好方案。 自加减go中没有前置的自加减运算符。并且后置的自加减不能与其他表达式出现在同一语句中。 1234i := 0++i // syntax error: unexpected ++fmt.Println(data[i++]) // syntax error: unexpected ++, expecting :i++ // ok 数据比较可以用==做数据比较的有： 基本数据类型：bool, byte, ruue, int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, float32, float64, complex, complex64, complex128, string, 指针类型 基本数据类型的数组。 只包含基本数据类型的数据结构。 对于不能用==比较的，可以使用reflect.DeepEqual()方法来实现。 对于字符串（[]byte或者string）的比较，若不区分大小写，可以使用bytes和strings包的ToUpper()或者ToLower()函数预处理。对于英语文本，这么做是没问题的，但对于许多其他的语言来说就不行了。这时应该使用 strings.EqualFold()和 bytes.EqualFold()。 如果你的byte slice中包含需要验证用户数据的隐私信息（比如，加密哈希、tokens等），不要使用 reflect.DeepEqual()、 bytes.Equal()，或者 bytes.Compare()，因为这些函数将会让你的应用易于被定时攻击。为了避免泄露时间信息，使用 &#39;crypto/subtle&#39;包中的函数（即， subtle.ConstantTimeCompare()）。 字符串String类型的不可为nilstring类型的零值是””，而不是nil。将string类型变量赋值为nil，或者与nil做比较，会得到编译错误 1234var s strings = nil // cannot use nil as type string in assignmentif s == nil &#123; // invalid operation: x == nil (mismatched types string and nil)&#125; String不可变 String 是带有一些附加属性的只读的字节片，不能对其中的单个字符进行修改 12x := &quot;text&quot;x[0] = &apos;T&apos; // cannot assign to x[0] String的长度 123s := &quot;你好&quot;fmt.Println(len(s)) // 6fmt.Println(utf8.RuneCountInString(s)) // 2 集合可以对nil的slice进行添加操作，但是map不行 12345var s []intvar m map[int]strings = append(s, 1) // okm[1] = &quot;one&quot; // panic 数组、切片的for…range返回是两个值每次迭代返回两个值，第一个是索引号，第二个才是元素数据。 1234x := []string&#123;&quot;a&quot;,&quot;b&quot;,&quot;c&quot;&#125;for v := range x &#123; fmt.Println(v) //prints 0, 1, 2&#125; 数组、切片的for…range的返回值是元素数据的副本对range返回的值进行修改，并不会影响集合中的原数据。 123456s := []int&#123;1, 2, 3&#125;for _, v := range s &#123; v = 10 _ = v&#125;fmt.Println(s) // prints [1 2 3] good code: 12345s := []int&#123;1, 2, 3&#125;for i := range s &#123; s[i] = 10&#125;fmt.Println(s) // prints [10 10 10] slice中的隐藏数据当你重新划分一个slice时，新的slice将引用原有slice的数组。如果你忘了这个行为的话，在你的应用分配大量临时的slice用于创建新的slice来引用原有数据的一小部分时，会导致难以预期的内存使用。bad code: 1234func get() []byte &#123; raw := make([]byte,10000) return raw[:3]&#125; 为了避免这个陷阱，你需要从临时的slice中拷贝数据（而不是重新划分slice） 123456func get() []byte &#123; raw := make([]byte,10000) res := make([]byte,3) copy(res,raw[:3]) return res&#125; slice数据被破坏slice重新划分后，引用的是原来的数组，对新slice的修改，会影响到原数据。 12345678base := []int&#123;1, 2, 3, 4&#125;s1 := base[:2]s2 := base[:3]s2[0] = 11fmt.Println(s1) // print: [11 2]fmt.Println(s2) // print: [11 2 3] 复合字面量的多行表示时缺少逗号复合字面量（数组、切片、字典、结构体）最后元素不跟上}需要加上,。 12345_ = []int&#123;1, 2&#125;_ = []int&#123; 1, 2 // syntax error: need trailing comma before newline in composite literal&#125; 更新map的值如果你有一个struct值的map，你无法更新单个的struct值。 123456type data struct &#123; name string&#125;m := map[string]data &#123;&quot;x&quot;:&#123;&quot;one&quot;&#125;&#125;m[&quot;x&quot;].name = &quot;two&quot; //error: cannot assign to m[&quot;x&quot;].name good code: 123v := m[&quot;x&quot;]v.name = &quot;two&quot;m[&quot;x&quot;] = v 控制跳出多层循环 123456loop:for i:=0; i&amp;lt;3; i++ &#123; for j:=0; j&amp;lt;3; j++ &#123; break loop &#125;&#125; for中的迭代变量和闭包for语句中的迭代变量在每次迭代时被重新使用。这就意味着你在 for循环中创建的闭包（即函数字面量）将会引用同一个变量（而在那些goroutine开始执行时就会得到那个变量的值） 12345678data := []int&#123;1, 2, 3&#125;for _,v := range data &#123; go func() &#123; fmt.Println(v) &#125;()&#125;time.Sleep(3 * time.Second)//goroutines print: 3, 3, 3 修正： 12345678data := []int&#123;1, 2, 3&#125;for _,v := range data &#123; go func(x int) &#123; fmt.Println(x) &#125;(v)&#125;time.Sleep(3 * time.Second)//goroutines print: 1, 2, 3 switch语句中的Fallthrough不同于其他语言，go中的switch中的每个case语句执行完后默认终止，而不需要break来终止。若希望继续执行下一个case，加上fallthrough 1234567891011isSpace := func(ch byte) bool &#123; switch(ch) &#123; case &apos; &apos;: // error hear case &apos;\t&apos;: return true &#125; return false&#125;fmt.Println(isSpace(&apos;\t&apos;)) //prints true (ok)fmt.Println(isSpace(&apos; &apos;)) //prints false (not ok) 修正： 123456switch(ch) &#123;case &apos; &apos;: fallthroughcase &apos;\t&apos;: return true&#125; go中的一个case中允许多个表达式，所以还可以这么写： 1234switch(ch) &#123;case &apos; &apos;, &apos;\t&apos;: return true&#125; 函数函数参数的数组是值传递函数调用参数的数组是对原数组的拷贝，函数中修改数组，不影响原数组。 123456x := [3]int&#123;1,2,3&#125;func(arr [3]int) &#123; arr[0] = 7 fmt.Println(arr) //prints [7 2 3]&#125;(x)fmt.Println(x) //prints [1 2 3] (not ok if you need [7 2 3]) 可以使用数组指针或者切片实现函数中修改原数组 defer函数调用参数的求值被defer的函数的参数会在defer声明时求值，而不是在函数实际执行时。 123var i int = 1defer fmt.Println(i) // print: 1i++ 通道关闭的channel的读写对关闭的channel，读操作得到零值；写操作触发异常 nil channel的读写读写nil channel永远阻塞 12345var ch chan intgo func() &#123; &amp;lt;- ch&#125;()ch &amp;lt;- 1 12345var ch chan intgo func() &#123; ch &amp;lt;- 1&#125;()&amp;lt;- ch 输出： 12345fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan receive (nil chan)]:...goroutine 5 [chan send (nil chan)]: 并发应用退出时协程未结束应用程序退出时并不会等待线程完成结束。 错误： 123456789101112131415workFun := func(id int) &#123; defer wg.Done() fmt.Printf(&quot;work [%v] start\n&quot;, id) time.Sleep(time.Second) fmt.Printf(&quot;work [%v] over\n&quot;, id)&#125;for i := 0; i &amp;lt; 2; i++ &#123; go workFun(i)&#125;fmt.Println(&quot;Bye&quot;)输出：Bye 修正： 1234567891011121314151617181920212223var wg sync.WaitGroupworkFun := func(id int) &#123; defer wg.Done() fmt.Printf(&quot;work [%v] start\n&quot;, id) time.Sleep(time.Second) fmt.Printf(&quot;work [%v] over\n&quot;, id)&#125;for i := 0; i &amp;lt; 2; i++ &#123; wg.Add(1) go workFun(i)&#125;wg.Wait()fmt.Println(&quot;Bye&quot;)输出：work [0] startwork [1] startwork [0] overwork [1] overBye 阻塞的Goroutine和资源泄露 12345678func First(query string, replicas ...Search) Result &#123; c := make(chan Result) searchReplica := func(i int) &#123; c &amp;lt;- replicas[i](query) &#125; for i := range replicas &#123; go searchReplica(i) &#125; return &amp;lt;-c&#125; 函数启动多工作流并发进行搜索功能，第一个搜索成功的协程将结果发送到结果通道c处。那其他协程呢？将会阻塞而导致资源的泄露。不错的解决方法是使用一个有 default情况的 select语句和一个保存一个缓存结果的channel。 default情况保证了即使当结果channel无法收到消息的情况下，goroutine也不会堵塞。 12345678910111213func First(query string, replicas ...Search) Result &#123; c := make(chan Result,1) searchReplica := func(i int) &#123; select &#123; case c &amp;lt;- replicas[i](query): default: &#125; &#125; for i := range replicas &#123; go searchReplica(i) &#125; return &amp;lt;-c&#125; 协程调度有可能会出现这种情况，一个无耻的goroutine阻止其他goroutine运行。当你有一个不让调度器运行的 for循环时，这就会发生。 12345678done := falsego func()&#123; done = true&#125;()for !done &#123; &#125;fmt.Println(&quot;done!&quot;) 只要for循环中没有会触发调度的代码，主协程就永远占用CPU而不让其他协程被调度。该例子在单核下会死循环，若在多核机子上运行，可以添加runtime.GOMAXPROCS(1)来限制工作数。 HTTP关闭HTTP响应使用标准http库发起请求时，得到一个httpx响应变量。处理完后需要关闭响应body，即使没有读取它。还有需要注意的是关闭的地方。如： 1234567resp, err := http.Get(&quot;https://api.ipify.org?format=json&quot;)// defer resp.Body.Close() // 1: not hereif err != nil &#123; return err&#125;defer resp.Body.Close() // 2: ok here/* 响应处理... */ 大多情况下，HTTP响应失败时，resp变量是nil，err是non-nil。在1处关闭会引发runtime panic。 参考资料http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang编程技巧]]></title>
    <url>%2F2018%2F04%2F21%2Fgolang-trick%2F</url>
    <content type="text"><![CDATA[Golang编程技巧数组、切片、字符串截取截取的新变量与就变量共用一个数组结构，不需要额外分配。 12a := [...]int&#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;a1 := a[1,3] // a1 = [2,3] 使用`创建避免转义 使用字节数组或缓冲区可以提升字符串连接的速度在 Go 语言中字符串是只读的，这表示每次当你使用 str = str + &quot;something&quot; 时，实际上创建了一个新的字符串对象。如果你寻求代码的最高效率，这里应该使用字节缓冲区来替代，例如： 123456str := &quot;something&quot;buf := bytes.NewBufferString(str)for i := 0; i &amp;lt; 1000; i++ &#123; buf.Write([]byte(randomString()))&#125;fmt.Println(buf.String()) 显式标识结构实现的接口 直观表现实现的接口 编译时候能够检查是否有遗漏实现 接口方法变化后也能很快地检查出来 123456789type VolumePlugin interface &#123; ...&#125;type rbdPlugin struct &#123; ...&#125;var _ VolumePlugin = &amp;amp;rbdPlugin&#123;&#125; // 检查rbdPlugin是否实现了VolumePlugin接口 空结构体的妙用空结构体struct{}占用0的空间。在只作为信号通知的通道中，可以定义空结构体的通道 12ch := make(chan struct&#123;&#125;)ch &amp;lt;- struct&#123;&#125;&#123;&#125; Sets实现 golang的基本数据结构中并没有Set结构，但是可以使用map来实现。 123type HashSet map[interface&#123;&#125;]bool或type HashSet map[interface&#123;&#125;]struct&#123;&#125; http打桩 httptest包中提供了HTTP的桩函数。 12testServer := httptest.NewServer(&amp;amp;fakeHandler)defer testServer.Close()]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alpine镜像制作的应用报not found问题解决]]></title>
    <url>%2F2018%2F04%2F21%2Fnot-found-in-alpine%2F</url>
    <content type="text"><![CDATA[Alpine镜像最为最小的镜像，深受笔者喜欢。但是其小体积，是以丢弃工具、包为代价，在使用时候经常碰到问题。其中命令Not found是在以Alpine为基础制作应用镜像时碰到的一个经常性问题。 问题下面以制作fio应用镜像为例。（真实的fio并不是这么制作的，在这做了简化以方便提出问题）。我们编写Dockerfile 123FROM alpine:3.4ADD fio /usr/local/bin/fio build成镜像名叫fio，运行此镜像： 12$ docker run fio fio -hsh: fio: not found 但是在容器中我们确实可以看到/usr/local/bin/fio是存在的，并且有执行权限。 解决该问题由于Alpine镜像中缺少glibc包引起的，见问题。可以再这里找到该包。回到我们docker build目录，下载glibc以及证书。 12wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apkwget -q -O sgerrand.rsa.pub https://raw.githubusercontent.com/sgerrand/alpine-pkg-glibc/master/sgerrand.rsa.pub 修改Dockerfile 12345678FROM alpine:3.4# 安装glibcADD sgerrand.rsa.pub /etc/apk/keys/sgerrand.rsa.pubCOPY glibc-2.25-r0.apk glibc-2.25-r0.apkRUN apk add glibc-2.25-r0.apk &amp;amp;&amp;amp; rm glibc-2.25-r0.apk## 继续安装应用... 再次构建后运行，程序正常。]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos下Git颜色显示以及自动提示]]></title>
    <url>%2F2018%2F04%2F21%2FGit-under-centos%2F</url>
    <content type="text"><![CDATA[之前一直在用Ubuntu和Windows上使用git，git的颜色显示和命令补全功能都能提升效率。现在换到centos上后，竟然没有了这两功能，倍感不爽。其实可以通过简答的配置，让它回来。 颜色设置修改~/.gitconfig，添加下面内容。 1234[color] diff = auto status = auto branch = auto 命令补齐git的命令补齐脚本其实已经存在/etc/bash_completion.d/git，只要source以下这个文件就行。也可以写在/etc/profile或者~/.bashrc。笔者喜欢新建个/etc/profile.d/git.sh，然后在文件中写上 1source /etc/bash_completion.d/git]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux_prompt_with_git]]></title>
    <url>%2F2018%2F04%2F17%2FLinux-prompt-with-git%2F</url>
    <content type="text"><![CDATA[在window的git bash中，进入git目录会在提示符上显示git信息，如 12用户名@主机名 MINGW64 /e/projects/kubernetes/src/k8s.io/kubernetes ((v1.9.0))$ 现在要在Linux上也实现这种显示。 准备安装git 修改修改~/.bashrc文件，在最后添加 1export PS1='\[\033[0;32m\]\u@\h\[\033[0;33m\] \w\[\033[36m\] $(__git_ps1 "(%s)") \[\033[01;35m\]\n\$\[\033[0m\] ' 保存退出。 验证打开新终端，命令提示符变化，如 12root@yjh-dev /work/projs/kubernetes ((v1.10.0))# 自定义格式也可以按照自己的风格修改PS1的值。PS1中的变量介绍如下123456789101112\d ：#代表日期，格式为weekday month date，例如：&quot;Mon Aug 1&quot;\H ：#完整的主机名称\h ：#仅取主机的第一个名字\t ：#显示时间为24小时格式，如：HH：MM：SS\T ：#显示时间为12小时格式\A ：#显示时间为24小时格式：HH：MM\u ：#当前用户的账号名称\v ：#BASH的版本信息\w ：#完整的工作目录名称\W ：#利用basename取得工作目录名称，所以只会列出最后一个目录\# ：#下达的第几个命令\$ ：#提示字符，如果是root时，提示符为：# ，普通用户则为：$ 颜色的格式如下 1\033[字背景颜色;文字颜色m 颜色代码如下 前景色 背景色 黑色 30 40 红色 31 41 绿色 32 42 黄色 33 43 蓝色 34 44 紫红色 35 45 青蓝色 36 46 白色 37 47 控制选项： 12345678910111213141516171819 \33[0m 关闭所有属性 \33[1m 设置高亮度 \33[4m 下划线 \33[5m 闪烁 \33[7m 反显 \33[8m 消隐 \33[30m — \33[37m 设置前景色 \33[40m — \33[47m 设置背景色 \33[nA 光标上移n行 \33[nB 光标下移n行 \33[nC 光标右移n行 \33[nD 光标左移n行 \33[y;xH设置光标位置 \33[2J 清屏 \33[K 清除从光标到行尾的内容 \33[s 保存光标位置 \33[u 恢复光标位置 \33[?25l 隐藏光标 \33[?25h 显示光标]]></content>
  </entry>
  <entry>
    <title><![CDATA[awesome]]></title>
    <url>%2F2018%2F04%2F09%2Fawesome%2F</url>
    <content type="text"><![CDATA[git配置1234567891011121314151617GIT_SSL_NO_VERIFY=truegit config --global http.sslVerify falsegit config --global core.autocrlf falsegit config --global core.safecrlf truegit config --global core.editor vimgit config --global color.diff autogit config --global color.status autogit config --global color.branch autogit config --global credential.helper store # 保存密码git config --global user.name &quot;xxx&quot;git config --global user.email &quot;xxx&quot;git config --global http.proxy xxxgit config --global http.postBuffer 52428800000git commit --amend --author=&quot;ikaven1024 &lt;ikaven1024@gmail.com&gt;&quot; 拉取部分代码12git config core.sparsecheckout true #开启sparse cloneecho &quot;devops&quot; &gt;&gt; .git/info/sparse-checkout #设置过滤条件，*表示所有，!表示匹配相反的 yum清缓存1yum makecache docker代理/usr/lib/systemd/system/docker.service: 1Environment=&quot;HTTP_PROXY=http://10.194.209.5:3128&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker.hikvision.com.cn&quot; docker配置12sudo groupadd dockersudo usermod -aG docker $USER 12345678910111213mkdir -p /etc/docker &amp;&amp; cat &gt;/etc/docker/daemon.json &lt;&lt;-EOF&#123; &quot;host&quot;: &quot;unix:///var/run/docker.sock tcp://0.0.0.0:2375&quot;, &quot;insecure-registries&quot;: [&quot;xxx&quot;], &quot;registry-mirrors&quot;: [&quot;xxx&quot;], &quot;log-level&quot;: &quot;debug&quot;, &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;200m&quot;, &quot;max-file&quot;: &quot;1&quot; &#125;&#125;EOF Boot2Docker用户名密码docker tcuserroot docker用户下执行sudo -i k8s12kubectl cluster-infoprintf &quot;%-20s %-50s %-15s %-20s %-20s \n&quot; NameSpace &quot;Pod Name&quot; Status &quot;Pod IP&quot; &quot;Host IP&quot; `kubectl get pod --output go-template --template=&quot;&#123;&#123;range .items&#125;&#125; &#123;&#123;.metadata.namespace&#125;&#125; &#123;&#123;.metadata.name&#125;&#125; &#123;&#123;.status.phase&#125;&#125; &#123;&#123;.status.podIP&#125;&#125; &#123;&#123;.status.hostIP&#125;&#125;&#123;&#123;end&#125;&#125;&quot; --all-namespaces` 编译关键组件： 1make WHAT=&apos;cmd/kube-apiserver cmd/kube-controller-manager cmd/kubelet cmd/kube-proxy cmd/kubectl plugin/cmd/kube-scheduler&apos; RBDrbd –pool rbd –id admin -m 192.168.1.187 –key=AQA0xWtYn98iOxAAMSsJbhGwuxyFVg9aIAvFoA== ls 代码统计利器cloc SHELL1basepath=(cd `dirname 0`; pwd) go vendor123go get -u -v github.com/kardianos/govendorgovendor initgovendor add +external ansible123ansible localhost -m setupansible all -m shell -a date dns配置12/etc/resolv.confnameserver xxx.xxx.xxx.xxx screen12345// 进入screensu stackscript /dev/nullscreen -lsscreen -x stack]]></content>
      <tags>
        <tag>awesome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-source-read]]></title>
    <url>%2F2018%2F04%2F09%2Fk8s-source-read%2F</url>
    <content type="text"><![CDATA[系统架构 代码结构12345/-- |-- cmd/ |-- hack/ |-- pkg/ |-- pluging/ 源码阅读ServiceController。 Scheduler 参考]]></content>
      <tags>
        <tag>k8s</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-1.6-gpu]]></title>
    <url>%2F2018%2F04%2F09%2Fk8s-1-6-gpu%2F</url>
    <content type="text"><![CDATA[k8s 1.6中GPU调度验证1. 目的调研kubernetes 1.6版本中对GPU调度的支持，是否符合项目需求。 2. 环境物理环境：NVIDIA Tesla P4 *4nvdia驱动：NVIDIA-Linux-x86_64-375.51docker: 17.03.1-ceNVIDIA-docker: nvidia-docker-1.0.1-1.x86_64kubernetes: v1.6.4 3. 准备 安装NVIDIA驱动 这里需要注意依赖的版本不对，安装驱动时候会有问题。这里采用系统镜像IOS包中的rpm包。镜像挂载在/mnt目录。 新建本地源： 123456# vi /etc/yum.repos.d/local.repo[local_server]name=This is local repobaseurl=file:///mnt/enabeld=1gpgcheck=0 安装依赖 12yum install -y gcc kernel-develrpm -ivh /mnt/Packages/kernel-devel-3.10.0-514.el7.x86_64.rpm 安装驱动 1./NVIDIA-Linux-x86_64-375.51.run 准备库文件 在后面的GPU容器中需要挂载NVIDIA的驱动库。目前驱动文件分布比较零散。可以使用nvidia-docker帮我们收集库文件。 安装NVIDIA-Docker 1rpm -ivh nvidia-docker-1.0.1-1.x86_64.rpm 安装完后，需要启动nvidia-docker守护进程，并创建一个GPU容器。 123456789101112131415$ systemctl start nvidia-docker$ nvidia-docker run --rm nvidia/cuda nvidia-smiFri Jun 23 11:19:53 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.51 Driver Version: 375.51 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 Tesla P4 Off | 0000:02:00.0 Off | 0 || N/A 39C P8 7W / 75W | 0MiB / 7606MiB | 0% Default |+-------------------------------+----------------------+----------------------+| 1 Tesla P4 Off | 0000:03:00.0 Off | 0 || N/A 41C P8 7W / 75W | 0MiB / 7606MiB | 0% Default |+-------------------------------+----------------------+----------------------+ 可以看到生成了目录。这也是后面Pod需要挂载的目录。 12$ ls /var/lib/nvidia-docker/volumes/nvidia_driver/375.51bin lib lib64 这时候nvidia-docker就可以功成身退了。也可以卸载掉。 1systemctl stop nvidia-docker 这样我们就可以使用原始的docker启动GPU容器了： 123456789101112131415161718192021222324$ docker run --rm \ -v /var/lib/nvidia-docker/volumes/nvidia_driver/375.51:/usr/local/nvidia \ --device /dev/nvidiactl:/dev/nvidiactl \ --device /dev/nvidia-uvm:/dev/nvidia-uvm \ --device /dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools \ --device /dev/nvidia0:/dev/nvidia0 \ nvidia/cuda nvidia-smiSat Aug 12 03:42:08 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.51 Driver Version: 375.51 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 Tesla P4 Off | 0000:04:00.0 Off | 0 || N/A 50C P0 24W / 75W | 0MiB / 7606MiB | 2% Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ kubelet启动参数添加--feature-gates Accelerators=true，重启kubelet。 4. 验证部署yaml: 123456789101112131415161718192021# vi demo-1.yamlapiVersion: v1kind: Podmetadata: name: cuda-demo-1spec: containers: - name: cuda image: nvidia/cuda command: ["bash", "-c", "nvidia-smi &amp;&amp; while true; do sleep 1000; done"] imagePullPolicy: IfNotPresent resources: limits: alpha.kubernetes.io/nvidia-gpu: "1" volumeMounts: - name: nvidia-driver mountPath: /usr/local/nvidia volumes: - name: nvidia-driver hostPath: path: /var/lib/nvidia-docker/volumes/nvidia_driver/375.51 create后查看日志： 123456789101112131415161718# kubectl logs cuda-demo-1Mon Jun 26 03:11:06 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.51 Driver Version: 375.51 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 Tesla P4 Off | 0000:02:00.0 Off | 0 || N/A 37C P8 7W / 75W | 0MiB / 7606MiB | 0% Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ 表明给容器分配一个GPU卡成功。 在创建个cuda-demo-1资源量修改为2，查看Pod状态； 1234# kubectl get poNAME READY STATUS RESTARTS AGEcuda-demo-1 1/1 Running 0 6mcuda-demo-2 0/1 Pending 0 3s Pod处于Pending状态，通过describe，查看 123456# kubectl describe po cuda-demo-2...Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 27s 8 default-scheduler Warning FailedScheduling No nodes are available that match all of the following predicates:: Insufficient alpha.kubernetes.io/nvidia-gpu (3). 在我们的意料之内：因为GPU资源不足而调度失败。 删除cuda-demo-1后，cuda-demo-2正常running。 5. 补充 GPU配额值支持limits GPU在容器间隔离，并不共享 不支持GPU的部分调度，最小粒度是一张显卡 同化了GPU硬件，对于用户统一 6. 不足 需要预先准备好驱动库。目前通过nvidia-docker帮我们完成。 容易产生资源碎片化问题。 7. 结论相比kubernetes 1.3的GPU调度（一个主机只能支持一个GPU卡），1.6的调度有何很好的完善。基本概念都跟CPU、Memory一样，只不过GPU的最小粒度是卡。这在实际使用中会造成资源碎片问题，需要后续加强调度能力。基本满足目前的预言项目需求。 FAQ装了NV驱动后，没有生成/dev/nvidia-uvm，导致k8s不识别GPU.根据 https://www.zhihu.com/question/36588693 上的方法,运行一个Sample就行 http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-verifications]]></content>
      <tags>
        <tag>k8s</tag>
        <tag>accelerator</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s响应]]></title>
    <url>%2F2018%2F04%2F09%2Fk8s-response%2F</url>
    <content type="text"><![CDATA[资源不存在12345678910111213141516171819# curl -i 127.0.0.1:8080/api/v1/namespaces/aaHTTP/1.1 404 Not FoundContent-Type: application/jsonDate: Fri, 16 Jun 2017 07:50:48 GMTContent-Length: 231&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "namespaces \"aa\" not found", "reason": "NotFound", "details": &#123; "name": "aa", "kind": "namespaces" &#125;, "code": 404&#125; 请求超时创建数据错误123456789101112131415# curl -i -X POST 127.0.0.1:8080/api/v1/namespacesHTTP/1.1 400 Bad RequestContent-Type: application/jsonDate: Fri, 16 Jun 2017 07:55:08 GMTContent-Length: 301&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "the object provided is unrecognized (must be of type Namespace): couldn't get version/kind; json parse error: unexpected end of JSON input (\u003cempty\u003e)", "reason": "BadRequest", "code": 400&#125; 创建已存在12345678910111213141516171819# curl -i -H "Content-type: application/json" -X POST -d '&#123;"apiVersion":"v1","kind":"Namespace","metadata":&#123;"name":"kube-system"&#125;&#125;' 127.0.0.1:8080/api/v1/namespacesHTTP/1.1 409 ConflictContent-Type: application/jsonDate: Fri, 16 Jun 2017 08:17:05 GMTContent-Length: 259&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "namespaces \"kube-system\" already exists", "reason": "AlreadyExists", "details": &#123; "name": "kube-system", "kind": "namespaces" &#125;, "code": 409&#125; 路径不合法12345678910111213141516# curl -i -X POST 127.0.0.1:8080/api/v1/namespaces/aaHTTP/1.1 405 Method Not AllowedContent-Type: application/jsonDate: Fri, 16 Jun 2017 07:53:01 GMTContent-Length: 229&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "the server does not allow this method on the requested resource", "reason": "MethodNotAllowed", "details": &#123;&#125;, "code": 405&#125; url path上的名称与数据不符合123456789101112131415# curl -i -H "Content-type: application/json" -X POST -d '&#123;"apiVersion":"v1","kind":"Pod","metadata":&#123;"name":"testpod","namespace":"noexists"&#125;,"spec":&#123;"containers":[&#123;"name":"nginx","image":"nginx:1.10.1-alpine"&#125;]&#125;&#125;' 127.0.0.1:8080/api/v1/namespaces/default/podsHTTP/1.1 400 Bad RequestContent-Type: application/jsonDate: Fri, 16 Jun 2017 08:20:16 GMTContent-Length: 228&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "the namespace of the provided object does not match the namespace sent on the request", "reason": "BadRequest", "code": 400&#125; 删除不存在资源12345678910111213141516171819# curl -i -X DELETE 127.0.0.1:8080/api/v1/namespaces/aaaHTTP/1.1 404 Not FoundContent-Type: application/jsonDate: Fri, 16 Jun 2017 08:37:49 GMTContent-Length: 233&#123; "kind": "Status", "apiVersion": "v1", "metadata": &#123;&#125;, "status": "Failure", "message": "namespaces \"aaa\" not found", "reason": "NotFound", "details": &#123; "name": "aaa", "kind": "namespaces" &#125;, "code": 404&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[swarm-guide]]></title>
    <url>%2F2018%2F04%2F09%2Fswarm-guide%2F</url>
    <content type="text"><![CDATA[创建两个虚拟机12$ docker-machine create --driver virtualbox myvm1$ docker-machine create --driver virtualbox myvm2 登陆虚拟机，并以root权限修改配置 12$ docker-machine ssh myvm1$ sudo -i 创建Swarm集群12$ docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr 192.168.99.100:2377&quot;$ docker-machine ssh myvm2 &quot;docker swarm join --token &lt;token&gt; &lt;ip&gt;:&lt;port&gt;&quot; 创建123456789101112131415161718192021$ vi getstartedlab.ymlversion: "3"services: web: image: docker pull nginx:1.10.1-alpine deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet:$ docker-machine scp getstartedlab.yml myvm1:~$ docker-machine ssh myvm1 "docker stack deploy -c getstartedlab.yml getstartedlab" 查看12345678$ docker-machine ssh myvm1 &quot;docker stack ps getstartedlab&quot;ID NAME IMAGE NODE DESIRED STATEjq2g3qp8nzwx test_web.1 username/repo:tag myvm1 Running88wgshobzoxl test_web.2 username/repo:tag myvm2 Runningvbb1qbkb0o2z test_web.3 username/repo:tag myvm2 Runningghii74p9budx test_web.4 username/repo:tag myvm1 Running0prmarhavs87 test_web.5 username/repo:tag myvm2 Running 服务访问 滚动升级1docker service update --image redis:3.0.7 redis 封锁节点12docker node update --availability drain &lt;NODE-ID&gt;docker node update --availability active &lt;NODE-ID&gt; 概念stack &gt; service &gt; task 12345docker stack ls # List all running applications on this Docker hostdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # Run the specified Compose filedocker stack services &lt;appname&gt; # List the services associated with an appdocker stack ps &lt;appname&gt; # List the running containers associated with an appdocker stack rm &lt;appname&gt; # Tear down an application]]></content>
      <tags>
        <tag>docker</tag>
        <tag>swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 架构]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-arch%2F</url>
    <content type="text"><![CDATA[进程树：1234/usr/bin/dockerd └─docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock... └─docker-containerd-shim f195bb34b2a34e53f8d6... └─nginx: master process nginx -g daemon off; dockerdcontainerd是容器技术标准化之后的产物，为了能够兼容OCI标准，将容器运行时及其管理功能从Docker Daemon剥离。理论上，即使不运行dockerd，也能够直接通过containerd来管理容器。（当然，containerd本身也只是一个守护进程，容器的实际运行时由后面介绍的runC控制。） 1/usr/bin/dockerd docker-containerdcontainerd主要职责是镜像管理（镜像、元信息等）、容器执行（调用最终运行时组件执行）。 containerd向上为Docker Daemon提供了gRPC接口，使得Docker Daemon屏蔽下面的结构变化，确保原有接口向下兼容。向下通过containerd-shim结合runC，使得引擎可以独立升级，避免之前Docker Daemon升级会导致所有容器不可用的问题。 containerd独立负责容器运行时和生命周期（如创建、启动、停止、中止、信号处理、删除等） 1docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc docker-containerd-shim容器的代理，接受容器创建、删除等命令，管理容器进程。 1docker-containerd-shim f195bb34b2a34e53f8d6b38af405185e9ce3cf59c38a12545c1f1416bd7a162c /var/run/docker/libcontainerd/f195bb34b2a34e53f8d6b38af405185e9ce3cf59c38a12545c1f1416bd7a162c docker-runc runcOCI定义了容器运行时标准，runC是Docker按照开放容器格式标准（OCF, Open Container Format）制定的一种具体实现。 runC是从Docker的libcontainer中迁移而来的，实现了容器启停、资源隔离等功能。Docker默认提供了docker-runc实现，事实上，通过containerd的封装，可以在Docker Daemon启动的时候指定runc的实现。 containerd-shim通过run操作容器。创建完成后runc退出，容器进程由containerd-shim接管。容器内产生的孤儿进程也统一由containerd-shim接管。 使用runc运行容器12345678$ mkdir -p mycontainer/rootfs &amp;&amp; cd mycontainer# 生成rootfs$ docker export $(docker create nginx:1.10.1-alpine) | tar -C rootfs/ -xf -# 生成配置文件config.json$ docker-runc spec# 运行容器$ docker-runc run test/ # /* 进入容器 */]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 使用]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-use%2F</url>
    <content type="text"><![CDATA[版本说明 系统：CentOS Linux release 7.2.1511 (Core) 内核：3.10.0-327.el7.x86_64 docker信息： 1234Server Version: 17.06.2-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: true 安装准备在基于xfs文件系统使用overlay存储驱动时，需要格式化参数ftype=1。否则会出现容器内目录删除失败的问题，见issue#31283。但是CentOS 7.2安装中并未使用这个参数。这里使用一个空分区来重新格式化。 如下，/dev/sdb1是新的分区，用mkfs进行格式化： 1mkfs.xfs -n ftype=1 /dev/sdb1 然后将此分区挂载到docker目录上（最好写入fstab中）： 12mkdir -p /var/lib/docker/mount /dev/sdb1 /var/lib/docker/ 可以使用以下命令验证 1xfs_info /dev/sdb1 | grep ftype 使用extfs也不行，见issues#15314，和https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/7.2_release_notes/technology-preview-file_systems 安装docker12wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.06.2.ce-1.el7.centos.x86_64.rpmyum install -y docker-ce-17.06.2.ce-1.el7.centos.x86_64.rpm 也可以使用阿里源http://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/docker-ce-17.06.2.ce-1.el7.centos.x86_64.rpm 写入配置1234567891011mkdir -p /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; "insecure-registries": ["xxxx"], "log-driver": "json-file", "log-opts": &#123; "max-size": "200m", "max-file": "1" &#125;&#125;EOF 启动docker12systemctl enable dockersystemctl start docker FAQDockerfile中yum install失败问题 在Overlay存储驱动下，镜像里如果吗，没有安装yum-plugin-ovl，会出现： 123456FROM centos:7.2.1511RUN curl http://mirrors.aliyun.com/help/centos/7/CentOS-Base.repo &gt; /etc/yum.repos.d/CentOS-Base.repoRUN yum makecache &amp;&amp; yum install -y perlRUN yum makecache &amp;&amp; yum install -y vim docker build后出现错误： 1Rpmdb checksum is invalid: dCDPT(pkg checksums): vim-filesystem.x86_64 2:7.4.160-2.el7 - u 分析 见issure#10180 解决1： 添加RUN yum install -y yum-plugin-ovl 解决2 RUN touch /var/lib/rpm/* &amp;&amp; RUN yum install -y &lt;packages-to-installed&gt; too many links问题 在Docker build或者pull时候，出现以下错误： 1/data/docker/runtime/overlay/49d96405b7d1ab2cc1c9f815347cf9716c3088b2db10ca3d36a894948b1e1a5c/root/var/lib/yum/yumdb/p/cf1f195f6bf8d654d694b941ead72c4c51798536-pcre-8.32-15.el7_2.1-x86_64/checksum_type /data/docker/runtime/overlay/1044d44c019cdd45df59c6df727dfef476decdc976477ab1124c0a0bf5735e10/tmproot559734426/var/lib/yum/yumdb/p/cf1f195f6bf8d654d694b941ead72c4c51798536-pcre-8.32-15.el7_2.1-x86_64/checksum_type: too many links 分析 由于硬链接数超出限制，见issues#32732 解决 清理镜像，减少镜像层数。 RLimit系统默认的是1024:4096。如果没有修改过，docker会调整到Hard Limit。如果想要更大的，可以： 修改/etc/docker/daemon.json 123456789&#123; "default-ulimits": &#123; "nofile": &#123; "Name": "nofile", "Hard": 2048, "Soft": 1024 &#125; &#125;&#125; 目前的版本中对这一配置有以下bug，见issues#1513： 1unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives don&apos;t match any configuration option: default-ulimits 已有PR#32547。 修改/usr/lib/systemd/system/docker.servicevice中添加 1234[Service]LimitNOFILE=65535LimitNPROC=65535LimitCORE=infinity 重启docker 添加启动参数 123dockerd --default-ulimit nofile=65535:65535 --default-ulimit nproc=65535:65535或dockerd --default-ulimit nofile=65535 --default-ulimit nproc=65535 单个容器设置 上面都是设置全局的。也允许单个容器的是设置 1docker run --ulimit nofile=65535 ...]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码编译docker]]></title>
    <url>%2F2018%2F04%2F09%2Fbuild-docker%2F</url>
    <content type="text"><![CDATA[编译环境 go 1.8.3 make gcc Protoc 3.x 12wget -c https://github.com/google/protobuf/releases/download/v3.1.0/protoc-3.1.0-linux-x86_64.zipunzip protoc-3.1.0-linux-x86_64.zip -d /usr/local 版本 COMPONENT COMMIT ID VERSION dockerd 89658bed64c2a8fe05a978e5b87dbec409d57a0f v17.05.0-ce containerd 9048e5e50717ea4497b757314bad98ea3763c145 v0.2.8 runc 9c2d8d184e5da67c95d601382adf14862e4f2228 libnetwork 7b2b1feb1de4817d522cc372af149ff48d25028e 编译全家桶123git clone https://github.com/moby/moby.git $GOPATH/src/github.com/docker/dockercd docker $GOPATH/src/github.com/docker/dockergit checkout -q 89658bed64c2a8fe05a978e5b87dbec409d57a0f moby项目提供了全家桶编译，需要在docker环境下以容器方式编译。这里需要注意两点： 代理。需要连到外网。如有需要请设置代理。 docker代理 Dockerfile中代理。修改项目中根目录下的Dockerfile文件，添加代理的环境变量。 1ENV http_proxy="http://yourproxy" https_proxy="http://yourproxy" golang下载地址。Dockerfile中使用的是https://golang.org/dl/go${GO_VERSION}.linux-amd64.tar.gz，属于墙外地址，如不能翻墙，可以替换为golangtc的地址 1RUN curl -fsSL "https://www.golangtc.com/static/go/$&#123;GO_VERSION&#125;/go$&#123;GO_VERSION&#125;.linux-amd64.tar.gz" 编译全家桶： 1make binary DOCKER_BUILD_APT_MIRROR=mirrors.aliyun.com 这里使用了aliyun镜像来加速编译。 生成在bundles/binary-daemon/ 1234567docker-containerddocker-containerd-ctrdocker-containerd-shimdockerddocker-initdocker-proxydocker-runc RPM同样需要在以下文件中设置代理 1234Dockerfileman/Dockerfilecontrib/builder/rpm/amd64/centos-7/Dockerfilehack/make/build-rpm 以及在hack/make/build-rpm中的cat &gt; &quot;$DEST/$version/Dockerfile.build&quot; &lt;&lt;-EOF位置上添加代理设置。 然后执行： 1make rpm DOCKER_BUILD_PKGS=centos-7 编译结果在： 1bundles/17.05.0-ce/build-rpm/centos-7/RPMS/x86_64/ 安装 cp $GOPATH/src/github.com/docker/docker/contrib/udev/80-docker.rules /etc/udev/rules.d/80-docker.rules 复制二进制到/usr/local/bin下 groupadd docker 运行dockerd启动。 分组件编译下面介绍各个组件的分别构建方式。 docker组件间的版本要求很苛刻。在项目中一般都有写明需要其他组件的commit id。 比如，在moby中的hack/dockerfile/binaries-commits和containerd中的RUNC.md。 cli12345git clone https://github.com/docker/cli.git $GOPATH/src/github.com/docker/clicd $GOPATH/src/github.com/docker/climake binarymv build/docker-linux-amd64 /usr/local/bin/docker containerd123456git clone https://github.com/containerd/containerd.git $GOPATH/src/github.com/containerd/containerdcd $GOPATH/src/github.com/containerd/containerdgit checkout -q 9048e5e50717ea4497b757314bad98ea3763c145make BUILDTAGS=no_btrfsmake install dockerd编译需要btrfs头文件和库。这里禁用了btr。 生成二进制： containerd containerd-shim containerd-stress ctr runc runc的版本必须跟containerd中要求的一致。见https://github.com/containerd/containerd/blob/master/RUNC.md，其中要求： RUNC_COMMIT = 9c2d8d184e5da67c95d601382adf14862e4f2228 12345678# 安装libseccompyum install -y libseccomp-develgit clone https://github.com/opencontainers/runc $GOPATH/src/github.com/opencontainers/runccd $GOPATH/src/github.com/opencontainers/runcgit checkout -q 9c2d8d184e5da67c95d601382adf14862e4f2228make &amp;&amp; make install 如果不希望启动seccomp，则 12&gt; make BUILDTAGS=''&gt;]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 入门示例]]></title>
    <url>%2F2018%2F04%2F08%2FSpring-Cloud-Example%2F</url>
    <content type="text"><![CDATA[1. 服务注册中心 Eureka2. 服务注册3. 熔断器Hystrix4. 熔断器监控5. 配置中心6. 服务网关 Zuul7. 链路跟踪 Zipkin示例项目见：https://github.com/ikaven1024/SpringCloud-example]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>springcloud</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F04%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow 安装]]></title>
    <url>%2F2018%2F04%2F03%2FTensorflow_install%2F</url>
    <content type="text"><![CDATA[Tensorflow 安装12345678910yum install -y python-pipmkdir /root/.pipcat &gt; /root/.pip/pip.conf &lt;&lt;EOF[global]index-url = http://10.1.14.235/python-pypi/simpletrusted-host = 10.1.14.235EOFpip install tesorflow TensorBoard12345678import tensorflow as tfa = tf.constant(2)b = tf.constant(3)x = tf.add(a, b)with tf.Session() as sess: writer = tf.summary.FileWriter('./graphs', sess.graph) print(sess.run(x))writer.close() # close the writer when you’re done using it tensorflow中一般有两步，第一步是定义图，第二步是在session中进行图中的计算。 常数12345678910111213141516171819202122232425262728# 常量tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)# 全零矩阵常量tf.zeros(shape, dtype=tf.float32, name=None)# 同纬全零矩阵常量tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)# 全1矩阵常量tf.ones(shape, dtype=tf.float32, name=None)# 同纬全1矩阵常量tf.ones_like(input_tensor, dtype=None, name=None, optimize=True)# tf.fill(dims, value, name=None)tf.linspace(start, stop, num, name=None)tf.range(start, limit=None, delta=1, dtype=None, name='range')# 随机数tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)# 截断正态分布tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None,name=None)tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None,name=None)tf.random_shuffle(value, seed=None, name=None)tf.random_crop(value, size, seed=None, name=None)tf.multinomial(logits, num_samples, seed=None, name=None)tf.random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None) 变量1234x = tf.Variable()x.initializer # 初始化x.eval() # 读取里面的值x.assign() # 分配值给这个变量 在使用变量之前必须对其进行初始化，初始化可以看作是一种变量的分配值操作。 1234# 一次性初始化所有的变量sess.run(tf.global_variables_initializer())# 初始化部分变量sess.run(w.initializer) # w是定义好的变量 取出变量 1w.eval(session=sess) 占位符tensorflow中一般有两步，第一步是定义图，第二步是在session中进行图中的计算。对于图中我们暂时不知道值的量，我们可以定义为占位符，之后再用feed_dict去赋值。 1tf.placeholder(dtype, shape=None, name=None) 例子： 12345a = tf.placeholder(tf.float32, shape=[3])b = tf.constant([5, 5, 5], tf.float32)c = a + bwith tf.Session() as sess: print(sess.run(c, feed_dict=&#123;a: [1, 2, 3]&#125;)) 选择逻辑1234res = tf.where( tf.less(residual, delta), # 条件 0.5 * residual**2, # 条件满足时 delta * residual - 0.5 * delta**2) # 条件不满足时 线性回归123456789101112131415161718192021# 输入输出占位符X = tf.placeholder(tf.float32, shape=[], name='input') # shape=[]表示标量(scalar)Y = tf.placeholder(tf.float32, shape=[], name='label')# 参数w = tf.get_variable('weight', shape=[], initializer=tf.truncated_normal_initializer())b = tf.get_variable('bias', shape=[], initializer=tf.zeros_initializer())Y_predicted = w * X + bloss = tf.square(Y - Y_predicted, name='loss') # 均方误差# 会自动求导，然后更新参数optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(100): total_loss = 0 for x, y in data: # 样本数据放在data _, l = sess.run([optimizer, loss], feed_dict=&#123;X: x, Y: y&#125;) total_loss += l print("Epoch &#123;0&#125;: &#123;1&#125;".format(i, total_loss / n_samples)) 完整源码见这里 模型构建步骤构建计算图 定义输入和输出的占位符(placeholder) 定义模型中需要用到的权重 定义推断模型，构建网络 定义损失函数作为优化对象 定义优化器进行优化 执行构件图 第一次进行运算的时候，初始化模型的所有参数 传入训练数据，可以打乱顺序 网络前向传播，计算出当前参数下的网络输出 根据网络输出和目标计算出loss 通过loss方向传播更新网络中的参数 结构化1234with tf.name_scope(name_of_taht_scope): # declare op_1 # declare op_2 # ...]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
</search>
